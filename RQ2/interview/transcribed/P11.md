**Interviewer:** Hello, thank you very much for taking the time to participate in this interview. Next, we will conduct a task review regarding the User Study. The first question is: When you were browsing the simulated website or installing servers, did any specific servers raise your suspicion, making you feel they might be malicious? Specifically, what aspects made you find them suspicious or suspect that there were issues with them?

**Interviewee:** Not at first. If the tasks hadn't prompted me to pay attention, I wouldn't have harbored malicious suspicions or concerns about these servers on my own.

---

**Interviewer:** Later, due to Task 2, what aspects did you examine to ultimately discover their suspicious nature?

**Interviewee:** I mainly started by reviewing the descriptions of these servers, and then proceeded to examine their specific source code, carefully looking for any strange code snippets within them.

---

**Interviewer:** Okay. The second question is: You found three malicious servers. How confident or certain do you feel that you would be able to identify potentially malicious MCP servers in the future?

**Interviewee:** That's hard to say. If I encounter a server with a massive codebase and complex function functionalities, like WeChat, I might not have enough patience to go through all the code completely.

---

**Interviewer:** I understand, a large codebase indeed increases the difficulty of discovery, making it hard to find malicious behavior. So, you're not very confident in identifying malicious MCPs.

---

**Interviewer:** Okay. The third question is: You discovered three malicious MCP servers. How did you make your judgments during the process of analyzing and identifying these three MCPs? Among the introduction, source code, and configuration method, which type of information did you find most helpful for your judgment?

**Interviewee:** The source code was the primary basis for judgment. I basically discovered the tricks by examining the source code. As for the other two aspects (introduction and configuration method), I didn't pay particular attention to them.

---

**Interviewer:** Okay, I will explain the roles of the other two types of information later. The next question is: While reviewing the source code, were there any specific code patterns, function calls, or code characteristics that particularly raised your alert and became your main points of focus?

**Interviewee:** For example, there were two quite obvious cases where they placed injected code snippets in very peculiar locations, such as the far right or bottom of the screen. This presentation method immediately made me suspect there might be an issue.

---

**Interviewer:** Okay. Next, I will explain the four types of malicious MCP attacks we found, their methods, and their characteristics. The first three were all found by you. The first one is "Time". The main issue with "Time" lies in its source code; it manipulates another tool via its description to perform certain operations. We call this attack method a "Puppet Attack," which involves using the MCP's description to mislead the Large Language Model (LLM) into controlling another tool to achieve attack objectives. This usually occurs in MCP environments with multiple tools, not just the MCP itself.

**Interviewer:** The second is "Weather". As you mentioned earlier, it indeed hid a function at the very bottom, which is a malicious feature. Furthermore, there was also a malicious description on its far right. These two combined would induce the LLM to perform malicious operations, such as reading private information, and then transmitting that private information out through the function at the bottom. This method of directly attacking using a malicious tool or a malicious MCP server is what we call a "Tool Poisoning Attack." In other words, the tool itself is malicious.

**Interviewer:** The third is "Google Map". This case actually utilized description information. For example, we can see that the creator of "Google Map" is not called "Google" but "Googie". This is clearly an attempt to imitate the official publisher, leading users to mistakenly believe it's officially released. Its malicious method, as you said, involved URL concatenation to access a malicious URL. However, the purpose of accessing that malicious URL was to retrieve a malicious Prompt from it, and then return this Prompt obtained from the malicious URL to the LLM to achieve injection. In this way, the code itself appears to be free of any malicious Prompts. It acts as an attack vector.

**Interviewer:** The fourth is WeChat MCP. Its issue lies in its configuration method; its code itself is fine. Its configuration method is in server.config. The first problem point is that the npm source it pulls from is named `@modelcontextprotcol`, but "protcol" is actually misspelled, missing an "o". It's mimicking a source that looks very official but isn't. The second problem is that it uses `npx -y @latest`. This command causes the user to pull the latest code from this third-party hosting platform every time they run this server. This implies a possibility: initially, its source code and functionality were normal, and users had no issues for a while. Then, attackers uploaded malicious code, and when the user pulled it again the second time, they received the malicious code. This is what's known as a "Rug Pull" attack, similar to a "pig butchering" scam.

**Interviewer:** Now that I've introduced these four attack types: Tool Poisoning, Puppet Attack, Rug Pull, and Malicious Third-Party Resource Attack. How would you rank these four attacks in terms of exploitation difficulty and severity of harm?

**Interviewee:** I think Rug Pull should be the most harmful because this method genuinely compromises the entire protocol. As for the first two, like those involving prompts, if Large Language Models evolve to a more intelligent stage in the future, they might be able to identify such issues. Alternatively, during these requests, there might be some more prompting information that requires user confirmation, so these might be relatively easier to prevent.

---

**Interviewer:** Understood. Okay, the next section is about your views on the overall security of the MCP ecosystem. The first question is: In the past, or in the future, would you consider using AI Agents combined with MCP to manage your private data or resources? For example, project source code, personal notes, blockchain wallets, and other relatively important data and resources.

**Interviewee:** I feel that for anything involving money, and some relatively important chats, I probably still wouldn't use this method. However, for things like code or personal notes, schedules, etc., I might allow such a protocol to help me organize them.

**Interviewer:** Understood. The next question is, have you used MCP in the past?

**Interviewee:** I have, to some extent.

**Interviewer:** When you used it, you must have noticed that it would pop up a prompt, telling you what permissions it was requesting, and which MCP server it was about to call, right? Would you carefully examine the specific permissions it applied for, what it intended to do, and its operational details?

**Interviewee:** Yes. I would look; it usually also states what it wants to do, what commands it wants to execute, etc. I would take a brief look.

**Interviewer:** Understood. And the next question is, for our user simulation, the simulated website we created, which mimics some popular MCP server portals that display many MCPs. What role do you think such websites should play in ensuring user safety? Or what kind of security indicator information should they provide to earn user trust?

**Interviewee:** Actually, at first, I didn't know this website was developed by you; I thought it was a normal website. If these websites are designed like this, it indeed feels quite difficult to distinguish [between legitimate and malicious ones]. They might need some more official labels, or provide warnings during download to help with prevention.

**Interviewer:** Understood. For example, regarding the "Googie" case just now, if the website could display a prominent "Official" or similar label, users would trust it more.

**Interviewee:** Yes.

**Interviewer:** Understood. Alright, and the next question is, what kind of information, features, or claimed verification mechanisms displayed on such websites would increase your trust in an MCP server?

**Interviewee:** I think first, it's about the servers included on the website: their quantity, and then their professionalism. If it includes many official-looking servers, then I would feel that this website might be relatively secure. And ideally, it should also be like an app store, including a mechanism for other user reviews or ratings, which would make the entire ecosystem feel more complete.

**Interviewer:** Understood. Alright, then, what kind of features or measures would you hope for in the future to improve the security risks of MCP, allowing you to use it with greater peace of mind?

**Interviewee:** I feel a sandbox environment is quite necessary. That is, to be able to use it first in a virtual environment and then see if any problems arise.

**Interviewer:** Okay. The last question is, do you have any suggestions or areas for improvement regarding the overall design of our user study?

**Interviewee:** Let me think about that. At first, I thought that clicking "Try this server" on the website would either directly download it or jump into a virtual environment, allowing me to directly use the server. If there could be such a more intuitive interaction method, it would be more convenient.

**Interviewer:** Understood. However, because it involves some malicious MCPs, and for ethical considerations, we cannot allow users to actually install anything in such an environment. So, we designed it by assuming the user has already installed it, creating a simulated process.

**Interviewer:** Okay, thank you again for investing your time and effort in participating in this study and interview. This concludes our interview.