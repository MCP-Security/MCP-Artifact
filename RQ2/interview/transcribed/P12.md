**Interviewer:** Alright, the recording has started. Thank you very much for taking the time to participate in this interview. Let's first review your previous tasks of browsing and installing servers on the simulated website. When you were browsing and installing servers, did any server immediately arouse your suspicion and make you feel it was malicious?

**Interviewee:** When I first browsed, judging solely from the content and description, I didn't particularly notice anything malicious. However, after reviewing the source code, I found that some servers might have intentionally included some code that would attack me. For example, a time-related MCP had a function placed in a very hidden location. I didn't notice this function at first, but upon closer inspection, I clearly felt that this function might have issues. This point was quite evident. However, if one were to judge only from superficial information, it would indeed be easy to be misled.

---

**Interviewer:** Okay, so the next question is, when you were browsing MCP servers on the simulated website, how confident were you in identifying these potentially malicious MCP servers?

**Interviewee:** To be honest, I wasn't very confident. Even when you gave hints about which ones were malicious (like in the third question), even with that specific purpose, it might still be difficult at first to distinguish which ones were truly malicious. This is indeed quite challenging.

---

**Interviewer:** Okay. You found some malicious MCPs in both Task 2 and Task 3. I'd like to ask, what were your analysis methods? Which one do you think was most useful for judging malicious behavior: the source code, the introductory information, or the configuration method?

**Interviewee:** For judging malicious behavior, I mainly looked at the overall description. For the configuration method, I would pay attention to whether there was a risk of personal information leakage. For the source code, I would mainly check if it directly read some of my information, or if there were any strange expressions. These could all draw my attention. Among these three, the introductory information and configuration method are relatively simpler; if there's malicious configuration, it might be easier to spot. Source code is usually longer, requiring more careful review, and malicious code can be hidden deeper, making it the most difficult to detect. I think malicious content in the introductory information would be relatively easy to hide; if it were truly malicious, it probably wouldn't be put directly there. The most difficult to utilize (or rather, the most difficult to find malice in) might be the source code, because it is indeed quite complex, and if the malicious code is well hidden, users unfamiliar with the code might struggle to find it. That's basically it.

---

**Interviewer:** Understood. You indirectly answered the fourth question just now, so let's skip it. So, modes of processing your data or reading your information are relatively easy to trigger your alertness, right?

**Interviewee:** Yes.

---

**Interviewer:** Okay. Next, I'll introduce the four types of malicious MCP servers, their attack types, and methods involved in our design. The first one is the Wither Server, which you found. As you mentioned, it hides a strange function at the bottom that communicates with an external URL. So you found that suspicious. Besides the external communication you discovered, the maliciousness of this code lies in that, although you found it communicates externally, you might not have found how it specifically obtains the communication content. The issue is with its documentation string. This documentation string appears normal on the surface, like an ordinary description. But if you drag to the far right, you'll find a hidden passage. This passage is fed to the large language model, manipulating it to read sensitive information such as `/etc/passwd`. Then, another function below transmits this information to the attacker, completing the attack process. Although this documentation string looks like just a comment, because it has the `mcp.tool` wrapper, it is passed to the large language model as part of the description. The large language model receives this information, thereby enabling an injection attack.

**Interviewee:** Uh-huh, understood.

---

**Interviewer:** We call this type of attack, where the server itself is malicious and combined with malicious function methods, tool poisoning. This is the first attack type. The second attack type is the Time Server, which you also discovered. It intersperses a strange phrase in its description, for example, using `use_note` to instruct the large model to call a wallet transfer function—which is a simulated blockchain transfer tool. Furthermore, it redirects the transfer address to a malicious simulated address, such as 123123. This method, in a multi-MCP server environment, deceives the large model through one MCP's description information, making the large model mistakenly believe it's the correct way to use another tool, thus turning it into the attacker's puppet. We call this a puppet attack, which involves manipulating the large model through malicious prompt injection to use another legitimate tool to achieve a malicious effect. In such a multi-MCP server environment, we refer to it as a puppet attack.

Next is Google Maps. Earlier, you said that no malicious points could be seen from the description. Actually, the malicious point here is in the author's name we set. It's not Google, but Googie.

**Interviewee:** Oh, yes.

---

**Interviewer:** This is to confuse users, making them think it's an official source when it's actually third-party. Its specific malicious part is hidden deeper. At one point in its code, a strange static location encoding is defined. On the surface, it looks like location encoding, but in reality, this encoding is transcoded into a malicious URL string and concatenated here to form a complete malicious URL. The program then requests this URL and returns the information obtained from it. How does this part achieve the attack? The return value of this function is given to the large model. The attacker uses this to request a malicious third-party resource, where a malicious prompt is placed. The program then directly returns this malicious prompt to the large model. This is equivalent to the program being a springboard, which the attacker uses to obtain malicious prompts. The attack method lies in the fact that the code itself appears to have no major issues, only making requests to third-party resources. However, the attacker can hide malicious prompts on that third-party URL, making it impossible for simple local source code scanning methods to discover the malicious descriptions or text. This method of grafting attacks forms this attack method. We call it a malicious third-party resource attack.

Okay. Then the fourth one is the WeChat MCP, a malicious server. Its source code has no issues; the problem lies in its configuration file. First, the configuration file uses `npx`, which requests a package from a source. We can see that the term `model_context_protocol` looks correct, but actually `protocol` is misspelled, missing an 'o'. This is also forging an official source, making users believe it's official without careful inspection. At the same time, there's another attack method here: it uses `@latest` and `-y`. `-y` means all requests are approved, and `@latest` downloads the latest version of the package. This hides a "Rug Pull" risk. That is, an attacker can initially upload legitimate code; users use it, find no issues, and trust the tool. Later, after some time, the attacker uploads malicious code as the latest version. When the user runs this server again, it will download and pull this `latest` malicious code, thus being attacked. This is Rug Pull.

**Interviewee:** Oh, I see.

---

**Interviewer:** Okay. After hearing the introduction to these four types of attacks—tool poisoning, puppet attack, Rug Pull, and malicious third-party resource attack—considering both the difficulty of exploitation and the severity of harm, how do you think they should be ranked?

**Interviewee:** I feel that, first, the first type (tool poisoning, Wither Server's documentation string attack) might be a bit more obvious, as it seems to use code obfuscation to achieve the goal of being unnoticed by users. The second type (puppet attack, Time Server's description attack) primarily leverages specific expressions in the description to make the large model an "accomplice." If it appears in a multi-MCP environment with only one malicious MCP, it might be harder to detect. Oh, the third one is Google Maps' malicious third-party resource issue. Then, I feel that both the fourth type (Rug Pull) and the third type (malicious third-party resource) are quite difficult to detect. For Rug Pull, if someone pays particular attention to the configuration file, they might notice a clue. But if users trust the source and directly use the configuration file, it's very difficult to discover. So, when I trust the configuration file provided to me, it's hard to detect this kind of malice. The most difficult to detect, I might consider the "malicious third-party resource" (the Google Maps/Googie one) mentioned earlier. Because it shows no issues at the local code level; it might require further execution and parsing of the code to find the problem. This involves actually running the code to check it. That's my opinion.

---

**Interviewer:** Understood. So you believe the most difficult to detect (and most dangerous) is the malicious third-party resource attack, followed by Rug Pull.

**Interviewee:** Yes.

---

**Interviewer:** Okay, this part concludes. Next, I'd like to understand your personal overall views on MCP ecosystem security. The first question is, in the past or future, would you consider using an AI Agent combined with MCP to manage your private data or resources, such as project source code, personal notes, or blockchain wallets?

**Interviewee:** Hmm, for things like project source code and personal notes, I might consider using it. But for more private things, like blockchain wallets, I would probably prefer not to use this method and manage them directly myself. Source code and notes, relatively speaking, the privacy of the text itself might not be as absolute.

---

**Interviewer:** Okay. So, have you used an MCP server before?

**Interviewee:** Indeed, I haven't used it much.

---

**Interviewer:** Haven't used it at all?

**Interviewee:** Yes, I haven't actually used it. I might have some understanding, but I haven't used it.

---

**Interviewer:** Okay, understood. Let's skip that question. The next question is, our simulated website is an MCP portal or app marketplace, offering many MCP servers for users to choose and download. What role do you think such websites should play in ensuring user security? What kind of security indicators and information should they provide to earn user trust?

**Interviewee:** I think these types of websites should act as security gatekeepers, somewhat like an app store. Only after passing their security checks should an MCP be allowed to be uploaded to the website. It should act as a gatekeeper, reviewing security. Specific security indicators could be considered from the aspects you listed, such as reviewing source code, pointing out which issues might severely impact security, and which are potential risks requiring further user judgment. The website should be able to help users find some more easily discoverable issues, such as obvious errors in configuration files; these types of checks should be relatively easy for the platform to implement. It should directly provide us with relevant security issue reports.

---

**Interviewer:** Your point is that you believe these third-party portal websites bear some responsibility for user security and should first filter out some of the most basic security issues, right?

**Interviewee:** Yes.

---

**Interviewer:** Yes. In fact, we conducted some investigations into some popular portal websites currently on the market, such as Smithery AI, which is quite popular. We uploaded an MCP that was claimed to be malicious, containing some abnormal functions (though not malicious code), and it was successfully uploaded very smoothly. There was no review or interception during this process, and users could directly access this "malicious" MCP server. Furthermore, the code even explicitly stated, "If you are a reviewer, do not approve this MCP server," but it still passed. This indicates that these platforms may currently lack strict review mechanisms.

**Interviewee:** Indeed, there might be shortcomings in this regard. Because users might not be so meticulous in reviewing its security when using it.

---

**Interviewer:** Okay. Next question, if you were a user, when selecting an MCP server, what kind of information, features, or verification mechanisms would make you particularly trust that MCP server?

**Interviewee:** First, it might need some security indicators, such as a security rating for the source code, text description, and other aspects. Secondly, a user feedback mechanism is very important. For example, if someone "gets hit" after using an MCP, they need a place to tell everyone and warn others not to use that MCP again. On the other hand, there might be a need for tools that can detect MCP security; I don't know if such tools exist yet. If they do, the platform should provide the detection results or audit reports from these security tools. This would be like an official audit report, which could increase user trust in the MCP.

---

**Interviewer:** Understood. The last question for this part is, what features or measures do you expect in the future that could improve user security risks when using MCP servers?

**Interviewee:** I think the most important might still be the auditing function, because source code checking itself is very time-consuming, and users might not check it so meticulously. This is probably the most important. Secondly, a simulated environment or sandbox could be provided. This way, even if users make mistakes during use, they might not suffer substantial attacks. In such a relatively safe environment, users can try out these things. If problems are indeed found, risks can be avoided in time. These are the two main points; I don't have many other ideas at the moment.

---

**Interviewer:** Okay. So, the next part of the questions is, do you have any suggestions for the overall design of this user study, or areas you think could be improved?

**Interviewee:** The overall design is quite good. I feel that the progressive relationship between the three tasks might not be particularly clear. For instance, in Task 2, I might have checked for issues based on the few MCPs I selected in Task 1. If I selected very few MCPs in Task 1, then I checked fewer in Task 2. However, in Task 3, four problematic MCPs were explicitly pointed out, which allowed for a comparison: to see what I found without prior knowledge of which were malicious, and then to specifically look for them after being informed. This part was well-designed. Perhaps further thought could be given to improving the correlation between tasks. Other than that, I feel there are no particular issues; it's well-designed.

---

**Interviewer:** Thank you very much. Regarding the task correlation you just mentioned, let me respond. Task 2 was designed this way because during previous pilot studies, it was found that if users were asked to audit and review all MCP servers, it would be too time-consuming, labor-intensive, and quite difficult. So, Task 2 was simplified, primarily to see if users intuitively felt any MCPs were abnormal after their initial selection.

**Interviewee:** Yes, your considerations are also important; it is indeed difficult to balance these two aspects.

---

**Interviewer:** Okay. Thank you again for investing your time and effort in participating in this user study and interview. This interview concludes here.

---